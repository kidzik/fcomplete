\documentclass{article}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb} 

\newcommand{\cN}{\mathcal{N}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\bX}{\mathbf{X}}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\diag}{diag}

\title{Comparison of structured SVD\\ and sparse functional PCA}
\author{Lukasz, Trevor}
\begin{document}
\maketitle

\section*{Plan}

\begin{enumerate}
  \item Show that reduced-rank SVD approximates factor model
  \item Sparse reduced-rank rank
\end{enumerate}

\section{Fully observed functional reduced-rank model}
Assume we measure processes on some equidistributed grid $G$ of $d$ points on $[0,1]$. Let $b_1, b_2, ..., b_p$ be the first $p$ elements of some orthonormal basis of $L_2([0,1])$ evaluated on the $G$, i.e. $b_i \in \R^d$ and $b_i \perp b_j$ for $i \neq j$. Let $B = [b_1,b_2,...,b_p]$, i.e. $B \in \R^{d \times p}$. Let $\Theta \in \R^{p \times k}$ be a matrix of coefficients of $k$ components in the basis $(b_i)_{1 \leq i \leq p}$.

We assume 
\begin{align}\label{eq:model}
  Y \sim \cN(B\theta, B \Theta \Theta' B' + \sigma^2 I_d),
\end{align}
where $Y_i \in \R^{d}$, $\theta \in \R^{p}$ is a vector of coefficients of a population mean in the basis $B$. %, $\alpha_i \in \R^{1 \times k}$ such that $\alpha_i~\sim~\cN(0, D)$ is 'random effect' of subject $i$ with a diagonal $D \in \R^{k \times k}$ and $\varepsilon_i \sim \cN(0, \sigma I_d)$ is some observation noise.
\subsection{Factor model}
Let
\begin{equation}
X = B'Y \sim \cN(\theta, \Theta \Theta' + \sigma^2 I_p).\label{model:x}
\end{equation}
Let $X_1,X_2,...,X_n$ be observations from this distribution.
Let $S$ be the sample estimate of the covariance matrix of $X$. Assume the spectral decomposition $S = V \Lambda V'$.
Theorem 9.4.1 in Marida states that for a fixed $\sigma$, the likelihood is maximized by
\[
 \Theta = \Lambda_{\sigma^2} ^{1/2}V,
\]
where $\Lambda_{\sigma^2}$ is a diagonal matrix ``truncated'' by $\sigma^2$, i.e. $d_{ii} = \max(\lambda_{ii} - \sigma^2,0)$. We find the best $\sigma$ numerically.

\subsection{Truncated SVD}
Let $X_1,X_2,...,X_n$ be observations from \eqref{model:x} and $S$ be the sample covariance. Let $\bX = [X_1',X_2',...,X_n']'$. Then we can write the SVD as
\[
\bX = U\Lambda^{1/2}V'.
\]
Let
\[
\hat\bX = U\Lambda^{1/2}_{\sigma^2}V'.
\]

\subsection{Sparse functional PCA}
Likelihood of $Y_i$ can be written as
\[
Y_i \sim \cN(\theta B, \sigma^2 I_d + B \Theta D \Theta' B').
\]
Our goal is to find $\sigma, \theta, \Theta, D$ maximizing
\[
\prod_{i=1}^N \frac{1}{(2\pi)^{d/2} |\sigma^2I_d + B \Theta D \Theta' B'|^{1/2}} \exp\left\{ -(Y_i - \theta B)'(\sigma^2 I_d + B \Theta D \Theta'B' )^{-1} (Y_i -  \theta B) / 2\right\}.
\]
Assume $\alpha_i$ are known. Then the likelihood is
\[
\prod_{i=1}^N \frac{1}{(2\pi)^{d/2} \sigma^d |D|^{1/2}} \exp\left\{ -(Y_i - \theta B - \alpha_i\Theta B)'(Y_i -  \theta B - \alpha_i\Theta B) / 2\sigma^2 - \frac{1}{2}\alpha_i' D^{-1} \alpha_i \right\}.
\]
Maxmizing this expression is equivalent (TODO: check) to minimizing
\begin{align*}
\sum_{i=1}^N \left\{ (Y_i - \theta B - \alpha_i\Theta B)'(Y_i -  \theta B - \alpha_i\Theta B) + \sigma^2 \sum_{j=1}^k \frac{\alpha_{i,j}^2}{D_{jj}}\right\} =&\\
\sum_{i=1}^N \| Y_i - \theta B - \alpha_i\Theta B\|^2 + \sigma^2 \sum_{j=1}^k \frac{1}{D_{jj}}\sum_{i=1}^N\alpha_{i,j}^2 =&\\
\| Y - (\mathbf{1}\theta B + A\Theta B)\|_F^2 + \sigma^2 \| A D^{-1/2} \|_F^2,
\end{align*}
where $A = [\alpha_1,\alpha_2,...,\alpha_N]'$.
Thus, the algorithm solves
\begin{align}\label{eq:optpca}
\argmin_{\theta,A,\Theta}\| Y B' - ( \mathbf{1}\theta + A\Theta)\|_F^2 + \sigma^2 \| A D^{-1/2} \|_F^2.
\end{align}

\subsection{Structured SVD}
Given $N$ observations, model \eqref{eq:model} can be written in the matrix form
\[
Y = \mathbf{1}\theta B + A \Theta B + \varepsilon.
\]
Consider the optimization problem
\usepackage{graphicx}
\[
\argmin_{\theta, A, \Theta} \| Y - (\mathbf{1}\theta B + A \Theta B)\|_F^2.
\]
Since $B$ is orthonormal, the problem is equivalent to 
\[
\argmin_{\theta, A, \Theta} \| YB' - (\mathbf{1}\theta + A \Theta)\|_F^2. 
\]
The solution is given by the reduced-rank SVD of $YB'$. We get $U,V$ such that
\[
\mathbf{1}\theta + A \Theta = UV'.
\]
We can decompose it to 
\[
\theta = U_0V' \text{ and } \Theta = U_1 V',
\]
where $U_0$ is the mean of rows of $U$ and $U_1 = U - \mathbf{1}U_0$.

Now, suppose we don't know the rank of $A$ and we want to find a reduced-rank solution. We add the penalty term
\[
\argmin_{\theta, A, \Theta} \| YB' - (\mathbf{1}\theta + A \Theta)\|_F^2 + \lambda\|\mathbf{1}\theta + A \Theta\|_*
\]
which is equivalent to
\begin{align}\label{eq:optsvd}
\argmin_{\theta, A, \Theta} \| YB' - (\mathbf{1}\theta + A \Theta)\|_F^2 + \lambda\|A\|_*,
\end{align}
and again reduced-rank SVD gives solutions for different ranks depending on $\lambda$.
Note that
\[
\|A\|_* = \sum_{i = 1}^k s_i = \| A D^{-1/2} \|_F^2,
\]
so the solutions \eqref{eq:optpca} and \eqref{eq:optsvd} should be (roughly) equivalent as long as $\lambda = \sigma^2$.

\subsection{Simulation}

We take the grid of size $d = 51$ and a spline basis of $9$ functions (Figure \ref{fig:basis}. We generate observations from model $\eqref{eq:model}$ with $k = 9$ true components. We set $\Theta\Theta'$ to be a matrix with eigenvalues $\diag[1,0.9,0.5,e^{-3},...,e^{-8}]$. We observed values with uncorrelated gaussian noise with $\sigma^2 = 0.25$. The matrix is fully-observed.

\begin{figure}[h]
  \includegraphics[width=\linewidth]{images/simulation-basis}
  \caption{Basis on the grid $G$ of $d=51$ equidistributed points and its othronormalized equivalent.}
  \label{fig:basis}
\end{figure}

In functional PCA we run the procedure with different $K = 1,2,...,9$ and in Soft-Impute we run the estimation procedure with different $\lambda$. We present the best results in Figure \ref{fig:results}. We analyze two errors: mean squared distance (1) from the observed points ($M_O$) and (2) from the true processes ($M_T$). For now, no cross-validation -- only in-sample fit.

Preliminary results are presented in (Table \ref{tab:results}).
\begin{table}[h]
  \centering
\begin{tabular}{lcc}
                  & $M_O$ & $M_T$\\
\hline
Soft-Impute  & 0.91 (sd=0.006) & 0.97 (sd=0.07)\\ 
Sparse fPCA & 0.93 (sd=0.009) & 0.91 (sd=0.07)\\
\end{tabular}
  \caption{Results from only ten trials (TODO).}\label{tab:results}
\end{table}

Results from one of the simulations are presented in Figure \ref{fig:results}. In Figure \ref{fig:components} we plot components and in Figure \ref{fig:scores} we plot scores.


\begin{figure}[h]
  \includegraphics[width=\linewidth]{images/simulation-results}
  \caption{5 example curves. True processes (top-left), Observed processes (top-right). Soft-impute estimates (bottom-left) and sparse functional PCA estimates (bottom-right).}
  \label{fig:results}
\end{figure}

\begin{figure}[h]
  \includegraphics[width=\linewidth]{images/simulation-components}
  \caption{Components}
  \label{fig:components}
\end{figure}

\begin{figure}[h]
  \includegraphics[width=\linewidth]{images/simulation-scores}
  \caption{Scores}
  \label{fig:scores}
\end{figure}

\section{Sparse reduced-rank model}
TODO: Should be similar...
\end{document}
